{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,MaxAbsScaler\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pymongo import MongoClient\n",
    "# This connects us to the \"tripAdvisor_london_restaurant\" database, and the \"collection\" [think table] restaurant_reviews \n",
    "# in that database\n",
    "client = MongoClient()\n",
    "db = client.restaurant_gurugram\n",
    "collection = db.mumbai_reviews\n",
    "\n",
    "cursor = collection.find({}, {'_id':0,'id':0,'index':0})\n",
    "df = pd.DataFrame(data=list(cursor))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"name\"] = df[\"name\"].replace(r'([\\d]+)\\.','',regex=True)\n",
    "df[\"sÄ±ralama\"] = df[\"name\"].str.extract('([\\d]+)\\. ', expand=False)\n",
    "df = df.sort_values(by=[\"sÄ±ralama\"])\n",
    "df = df.drop(columns=[\"sÄ±ralama\"]) # 24103\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset =[\"name\",\"rating\",\"comments\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "val = df[\"loc\"].to_list()\n",
    "\n",
    "new =[]\n",
    "\n",
    "for v in val:\n",
    "    if(len(v)==2 or len(v)==1):\n",
    "        new.append(str(v[0]))\n",
    "    else:\n",
    "        new.append(str(v))\n",
    "df[\"loc\"] = new\n",
    "\n",
    "df.rating = df.rating.astype(\"int\")\n",
    "\n",
    "df[\"info\"] = df[\"info\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"info\"] = df[\"info\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "df = df.drop(columns=[\"index\"])\n",
    "\n",
    "df.rating = df.rating.apply(lambda x: int(x)/10)\n",
    "\n",
    "df[\"street\"] = df[\"loc\"].apply(lambda x : x.split(\",\")[0])\n",
    "df[\"postCode\"] = df[\"loc\"].apply(lambda x :x.split(\",\")[-1])\n",
    "\n",
    "df = df.drop(columns=[\"loc\"])\n",
    "name_list = list(df.name.unique())\n",
    "\n",
    "df1 = df[df[\"name\"].isin(name_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.barplot(df1.rating.value_counts().sort_values(ascending=True).index,\n",
    "                 y=df1.rating.value_counts().sort_values(ascending=True),palette=\"rainbow\")\n",
    "plt.title(\"Rating Distribution\")\n",
    "plt.xlabel(\"Number Of Stars\")\n",
    "plt.ylabel(\"Number Of Reviews\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.savefig(\"sent.jpeg\",dpi=300,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.rating!=3]\n",
    "\n",
    "import numpy as np\n",
    "df1['sentiment'] = np.where(df1['rating'] >= 4, 'positive', 'negative')\n",
    "\n",
    "df1.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "s_words= list(stopwords.words('english'))\n",
    "stop_words = list(STOPWORDS)+ [\"what\", \"us\", \"this\",\"well\",\"there\",\"much\",\"us\",\"and\",\"you're\",\"in\",\"where\",\"when\",\"just\",\"how\",\"is\",\"ha\",\"re\",\"are\"\n",
    "                              \"hi\",\"aren't\", 'couldn','could','couldnt',\"couldn't\",'did','had','have','must','does','should','was',\"it's\"\n",
    "                               \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", 'let', 'll',\"may\",'were','is','has','must',\n",
    "                               'mustn', 'rt', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn','realli','now','got','man','people','a',\n",
    "                               'becaus','caus',\"one\",\"im\",\"guy\",\"someone\",\"two\",\"nearby\",\"i\",\"he's\",\"she's\",\"we\",\"it\",\"they\",\"wouldnâ€™t\",\"i've\",\n",
    "                               'aren', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'sdidn', 've',\"will\",\"restaurant\"]\n",
    "\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    \n",
    "    sentence = []\n",
    "    s = \"\"\n",
    "    for word in txt.split():    \n",
    "        if(word not in stop_words):      \n",
    "            sentence.append(word)\n",
    "            s = ' '.join(sentence)\n",
    "    return s\n",
    "\n",
    "df1.comments = df1.comments.map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "nltk.download(\"wordnet\")\n",
    "def lem_words(text):\n",
    "    \n",
    "    return \" \".join([lemm.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "\n",
    "\n",
    "df1.comments = df1.comments.apply(lambda metin: lem_words(metin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.summary = df1.summary.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "\n",
    "df1.summary = df1.summary.map(alphanumeric).map(punc_lower)\n",
    "df1.comments = df1.comments.map(alphanumeric).map(punc_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(txt):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',txt)\n",
    "\n",
    "def remove_html(txt):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',txt)\n",
    "\n",
    "# U+1F970\n",
    "def remove_emoji(txt):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', txt)\n",
    "def remove(emoji):\n",
    "    em = re.compile(r\"ðŸ¥°\")\n",
    "    return em.sub(r\"\",emoji)\n",
    "def remove_blank_space(text):\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)\n",
    "def remove_blank2(text):\n",
    "    text = text.strip()\n",
    "    return text\n",
    "def remove_all(ReviewText):\n",
    "    ReviewText = ReviewText.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.replace('(\\xa0)', ' ') \n",
    "    ReviewText = ReviewText.replace(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', ' ') \n",
    "    return ReviewText\n",
    "\n",
    "    \n",
    "df1.comments = df1.comments.apply(remove_url)\n",
    "df1.comments = df1.comments.apply(remove_html)\n",
    "df1.comments = df1.comments.apply(remove_emoji)\n",
    "df1.comments = df1.comments.apply(remove)\n",
    "df1.comments = df1.comments.apply(remove_blank_space)\n",
    "df1.comments = df1.comments.apply(remove_blank2)\n",
    "df1.comments = df1.comments.apply(remove_all)\n",
    "df1.comments = df1.comments.map(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "\n",
    "# txt = ','.join(list(df1.comments.values))\n",
    "\n",
    "# # Create a WordCloud object\n",
    "# wordcloud = WordCloud(background_color=\"white\",stopwords = stop_words, \n",
    "#                       min_font_size = 5, width=800, height=400, \n",
    "#                       max_words=100, contour_width=3, contour_color='steelblue').generate(txt)\n",
    "\n",
    "# # Visualize the word cloud\n",
    "# print(\"--------Top 300 R - All Reviews-------------\")\n",
    "# wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud.to_file(\"a_reviews.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt = ','.join(list(df1[df1.sentiment==\"negative\"].comments.values))\n",
    "\n",
    "# # Create a WordCloud object\n",
    "# wordcloud = WordCloud(background_color=\"white\",stopwords = stop_words, \n",
    "#                       min_font_size = 5, width=800, height=400, \n",
    "#                       max_words=100, contour_width=3, contour_color='steelblue').generate(txt)\n",
    "# wordcloud.to_file(\"n_reviews.png\")\n",
    "# # Visualize the word cloud\n",
    "# print(\"--------Negative Reviews-------------\")\n",
    "# wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# txt = ','.join(list(df1[df1.sentiment==\"positive\"].comments.values))\n",
    "\n",
    "# # Create a WordCloud object\n",
    "# wordcloud = WordCloud(background_color=\"white\",stopwords = stop_words, \n",
    "#                       min_font_size = 5, width=800, height=400, \n",
    "#                       max_words=100, contour_width=3, contour_color='steelblue').generate(txt)\n",
    "\n",
    "# # Visualize the word cloud\n",
    "# print(\"--------Positive Reviews-------------\")\n",
    "# wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud.to_file(\"positive_reviews.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = stop_words + [\"food\",\"dinner\",\"menu\",\"service\",\"staff\",\"starter\",\"place\",\"meal\",\"lunch\",\"drink\",\"restaurant\",\"burger\",\"pub\",\n",
    "              \"waiter\",\"family\",\"wine\",\"main\",\"bar\",\"eat\",\"area\",\"evening\",\"pizza\",\"came\",\"went\",\"made\",\"dessert\",\"breakfast\",\n",
    "              \"cocktail\",\"table\",\"booked\",\"london\",\"way\",\"many\",\"think\",\"another\",\"took\",\"pasta\",\"fish\",\"dish\",\"pay\",\"going\",\n",
    "              \"dessert\",\"wife\",\"came\",\"go\",\"say\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "for txt in df1.comments.values:\n",
    "    for word in txt.split():\n",
    "        c[word] += 1\n",
    "set([w for (w, wc) in c.most_common()[:-29:-1]])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #stopwords2= stopwords+[\"TRY\\\\xa0\"]\n",
    "\n",
    "# txt = ','.join(list(df1[\"info\"].fillna(\" \").values))\n",
    "\n",
    "# # Create a WordCloud object\n",
    "# wordcloud = WordCloud(background_color=\"white\",stopwords = stop_words, \n",
    "#                       min_font_size = 5, width=800, height=400, \n",
    "#                       max_words=100, contour_width=3, contour_color='steelblue').generate(txt)\n",
    "# #wordcloud.to_file(\"restaurant_info.png\")\n",
    "# # Visualize the word cloud\n",
    "# print(\"--------Restaurant Information-------------\")\n",
    "# wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem_words(text):\n",
    "\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "df1.comments = df1.comments.apply(lambda txt: stem_words(txt))\n",
    "\n",
    "from textblob import TextBlob\n",
    "df1['polarity'] = df1['comments'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "\n",
    "mc = c.most_common(20)\n",
    "\n",
    "df2 = pd.DataFrame(mc,columns=[\"word\",\"freq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.bar(df2, x='word', y='freq',\n",
    "#              hover_data=['word', 'freq'], color='freq',\n",
    "#              title='Most Common 20 Words',\n",
    "#              height=400)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[\"word count\"] = df1.comments.str.len()\n",
    "\n",
    "# fig = px.histogram(df1, x=\"word count\", nbins=200, title='Word Count')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.histogram(df1, x=\"polarity\", nbins=20, title='Text Polarity')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sentiment = df1.sentiment.map({\"negative\":0,\"positive\":1})\n",
    "name_list = list(df1.groupby(\"name\")[\"sentiment\"].mean().sort_values(ascending=False).head(10).index)\n",
    "\n",
    "df1.groupby(\"name\")[\"polarity\"].mean().sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(15,10))\n",
    "# sns.barplot(df1.groupby(\"name\")[\"sentiment\"].mean().sort_values(ascending=True).head(5).index,\n",
    "#                  y=df1.groupby(\"name\")[\"sentiment\"].mean().sort_values(ascending=True).head(5),palette=\"rainbow\")\n",
    "# plt.xticks(rotation=30)\n",
    "# #plt.savefig(\"sent.jpeg\",dpi=300,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# fig = px.box(df1[df1.name.isin(name_list)], x=\"name\",y='polarity', color=\"name\",\n",
    "#              title=\"Polarity based On Restaurant Name\",\n",
    "#              hover_data=[\"polarity\"])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = df1.drop(columns=[\"users\"])\n",
    "df1 = df1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def model_produce(X,y,model,min_df,ngram_range):\n",
    "    m = model(stop_words=stopw, min_df=min_df,max_df=.85, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",ngram_range=ngram_range)\n",
    "    m2 = m.fit_transform(X)\n",
    "    # modeldf = pd.DataFrame(m2.toarray(), columns=m.get_feature_names())\n",
    "   # m3  = pd.concat([df1[\"polarity\"],modeldf],axis=1)\n",
    "    X_under, y_under = RandomUnderSampler(random_state=42).fit_sample(m2,y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.3, random_state=42,stratify = y_under)\n",
    "  \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "X = df1.comments\n",
    "y = df1.sentiment\n",
    "\n",
    "model = TfidfVectorizer\n",
    "ngram_range =(1,2)\n",
    "X_train, X_test, y_train, y_test = model_produce(X,y,model,1,ngram_range)\n",
    "\n",
    "\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def conf_matrix(actual, predicted):\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    sns.heatmap(cm, xticklabels=['predict Negative', 'predict Positive'], \n",
    "                yticklabels=['actual Negative', 'actual Positive'], annot=True,\n",
    "                fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
    "\n",
    "    true_neg, false_pos = cm[0]\n",
    "    false_neg, true_pos = cm[1]\n",
    "\n",
    "    accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
    "    precision = round((true_pos) / (true_pos + false_pos),3)\n",
    "    recall = round((true_pos) / (true_pos + false_neg),3)\n",
    "    f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
    "\n",
    "    cm_results = [accuracy, precision, recall, f1]\n",
    "    print(cm_results)\n",
    "    return cm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_list = []\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "kf = StratifiedKFold(n_splits=10, random_state=42,shuffle=True)\n",
    "def calculate_metrics(model, X_train, X_test, y_train, y_test):\n",
    "    begin = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    now =time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(model)\n",
    "    print('CV accuracy:', test_accuracy)\n",
    "    print('Precision:{:6.4f},   Recall:{:6.4f}, F1:{:6.4f}'.format(precision, \n",
    "                                                                   recall, f1))\n",
    "    cv_acc = cross_val_score(model, X_train, y_train, cv=kf,scoring=\"accuracy\").mean()\n",
    "    cv_f1 = cross_val_score(model, X_train, y_train, cv=kf,scoring=\"f1\").mean()\n",
    "    perform_list.append(dict([\n",
    "            (\"Model\" , model.__class__.__name__),\n",
    "            (\"Time x 1000\",(now-begin)*1000),\n",
    "            (\"Train Accuracy\", model.score(X_train,y_train)),\n",
    "            (\"Test Accuracy\", test_accuracy),\n",
    "            (\"Precision\" , precision ),\n",
    "            (\"recall\",recall),\n",
    "            (\"f1\",f1),\n",
    "            (\"CV Accuracy\",cv_acc),\n",
    "            (\"CV f1\",cv_f1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def plot_LSA(test_data, test_labels, savepath=\"PCA_demo.csv\", plot=True):\n",
    "        lsa = TruncatedSVD(n_components=2)\n",
    "        lsa.fit(test_data)\n",
    "        lsa_scores = lsa.transform(test_data)\n",
    "        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n",
    "        color_column = [color_mapper[label] for label in test_labels]\n",
    "        colors = ['blue','pink','pink']\n",
    "        if plot:\n",
    "            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "            red_patch = mpatches.Patch(color='blue', label='Negative')\n",
    "            green_patch = mpatches.Patch(color='pink', label='Positive')\n",
    "            plt.legend(handles=[red_patch, green_patch], prop={'size': 30})\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))          \n",
    "plot_LSA(X_train, y_train)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfVectorizer\n",
    "ngram_range = (1,1)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2  = model_produce(X,y,model,4,ngram_range)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))          \n",
    "plot_LSA(X_train2, y_train2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfVectorizer\n",
    "ngram_range =(1,2)\n",
    "\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3  = model_produce(X,y,model,4,ngram_range)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))          \n",
    "plot_LSA(X_train3, y_train3)\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  precision_score, recall_score, precision_recall_curve,f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "perform_list = []\n",
    "XGB = XGBClassifier()\n",
    "GBC = GradientBoostingClassifier()\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "LR2 = LogisticRegression()\n",
    "MNB = MultinomialNB()\n",
    "RF = RandomForestClassifier()\n",
    "BNB = BernoulliNB()\n",
    "GNB = GaussianNB()\n",
    "LSVC = LinearSVC()\n",
    "\n",
    "models = [LR,GBC,MNB,BNB,RF,XGB,LSVC]\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    calculate_metrics(model,X_train2, X_test2, y_train2, y_test2)\n",
    "    print('------------------Model Result :---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = pd.DataFrame(perform_list)\n",
    "per = per[[\"Model\",\"Time x 1000\",\"Train Accuracy\",\"Test Accuracy\",\"Precision\",\"recall\",\"f1\",\"CV Accuracy\",\"CV f1\"]]\n",
    "# per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mb2 = LogisticRegression() # LogReg, Multi, Bernoulli\n",
    "mb2.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred1 = mb2.predict(X_test2)\n",
    "\n",
    "conf_matrix(y_test2,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = MultinomialNB() # LogReg, Multi, Bernoulli\n",
    "mb.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred1 = mb.predict(X_test2)\n",
    "\n",
    "conf_matrix(y_test2,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, random_state=42,shuffle=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "parameters = {'alpha':np.linspace(0,9)}\n",
    "\n",
    "\n",
    "clf2 = GridSearchCV(mnb, parameters, n_jobs=5, \n",
    "                   cv=kf,\n",
    "                   scoring='accuracy',\n",
    "                   refit=True)\n",
    "\n",
    "clf2.fit(X_train2, y_train2)\n",
    "clf2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha = 2.2040816326530615)\n",
    "mb.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred1 = mb.predict(X_test2)\n",
    "\n",
    "conf_matrix(y_test2,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "clf2 = GridSearchCV(lr, grid, n_jobs=5, \n",
    "                   cv=kf,\n",
    "                   scoring='accuracy',\n",
    "                   refit=True)\n",
    "\n",
    "clf2.fit(X_train2, y_train2)\n",
    "clf2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 0.1, penalty = 'l2')\n",
    "lr.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred1 = lr.predict(X_test2)\n",
    "\n",
    "conf_matrix(y_test2,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = TfidfVectorizer(stop_words=stopw, min_df=4,max_df=.85, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "m2 = m.fit_transform(X)\n",
    "modeldf = pd.DataFrame(m2.toarray(), columns=m.get_feature_names())\n",
    "m3  = pd.concat([df1[\"polarity\"],modeldf],axis=1)\n",
    "X_under, y_under = RandomUnderSampler(random_state=42).fit_sample(m2,y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.3, random_state=42,stratify = y_under)\n",
    "\n",
    "eli5.show_weights(lr, vec=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier()\n",
    "GBC = GradientBoostingClassifier()\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "LR2 = LogisticRegression()\n",
    "MNB = MultinomialNB()\n",
    "RF = RandomForestClassifier()\n",
    "BNB = BernoulliNB()\n",
    "GNB = GaussianNB()\n",
    "LSVC = LinearSVC()\n",
    "\n",
    "models = [LR,GBC,MNB,BNB,RF,XGB,LSVC]\n",
    "\n",
    "\n",
    "m = CountVectorizer(stop_words=stopw, min_df=4,max_df=.85, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "m2 = m.fit_transform(X)\n",
    "X_under, y_under = RandomUnderSampler(random_state=42).fit_sample(m2,y)\n",
    "X_trainc, X_testc, y_trainc, y_testc = train_test_split(X_under, y_under, test_size=0.3, random_state=42,stratify = y_under)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    calculate_metrics(model,X_trainc, X_testc, y_trainc, y_testc )\n",
    "    print('------------------Model Result :---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(16, 16))          \n",
    "plot_LSA(X_trainc, y_trainc)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per2 = pd.DataFrame(perform_list)\n",
    "per2 = per2[[\"Model\",\"Time x 1000\",\"Train Accuracy\",\"Test Accuracy\",\"Precision\",\"recall\",\"f1\",\"CV Accuracy\",\"CV f1\"]]\n",
    "# per2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mb = MultinomialNB() # LogReg, Multi, Bernoulli\n",
    "mb.fit(X_trainc, y_trainc)\n",
    "\n",
    "y_pred1 = mb.predict(X_testc)\n",
    "\n",
    "conf_matrix(y_testc,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "parameters = {'alpha':np.linspace(0.0001,9)}\n",
    "\n",
    "\n",
    "clf2 = GridSearchCV(mnb, parameters, n_jobs=5, \n",
    "                   cv=kf,\n",
    "                   scoring='accuracy',\n",
    "                   refit=True)\n",
    "\n",
    "clf2.fit(X_train2, y_train2)\n",
    "clf2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha = 2.204157142857143)\n",
    "mnb.fit(X_trainc, y_trainc)\n",
    "\n",
    "y_pred1 = mb.predict(X_testc)\n",
    "\n",
    "conf_matrix(y_testc,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'alpha':np.linspace(0.1,1,10)}]\n",
    "\n",
    "\n",
    "clf = GridSearchCV(BernoulliNB(), parameters, n_jobs=5, \n",
    "                   cv=kf,\n",
    "                   scoring='accuracy',\n",
    "                   refit=True)\n",
    "clf.fit(X_trainc, y_trainc) # running the grid search\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(alpha = 0.30000000000000004)\n",
    "bnb.fit(X_trainc, y_trainc)\n",
    "\n",
    "y_pred1 = bnb.predict(X_testc)\n",
    "\n",
    "conf_matrix(y_testc,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = MultinomialNB().fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "y_pred1 = mb.predict(X_test2)\n",
    "\n",
    "lr_proba = lr.predict_proba(X_test2)\n",
    "nb_proba = mb.predict_proba(X_test2)\n",
    "nb_proba2 = mnb.predict_proba(X_testc)\n",
    "#l_propba = LSVC.predict_proba(X_test2)\n",
    "\n",
    "def plot_roc_curves():\n",
    "    plt.figure(figsize=(10,6))\n",
    "    lw = 2    \n",
    "    \n",
    "    # Logistic Regression\n",
    "    fpr, tpr, thresholds = roc_curve(y_test2, lr_proba[:,1], pos_label=1)\n",
    "    auc_lr = roc_auc_score(y_test2, lr_proba[:,1])\n",
    "    plt.plot(fpr, tpr, color='r',\n",
    "             lw=lw, label='LR-TFIDF, auc=%.3f' % auc_lr)\n",
    "         \n",
    "    \n",
    "    # Naive Bayes\n",
    "    fpr, tpr, thresholds = roc_curve(y_test2, nb_proba[:,1], pos_label=1)\n",
    "    auc_nbc = roc_auc_score(y_test2, nb_proba[:,1])\n",
    "    plt.plot(fpr, tpr, color='chartreuse',\n",
    "             lw=lw, label='Naive Bayes-TFIDF, auc=%.3f' % auc_nbc)\n",
    "\n",
    "    # Naive Bayes 2\n",
    "    fpr, tpr, thresholds = roc_curve(y_test2, nb_proba2[:,1], pos_label=1)\n",
    "    auc_nb = roc_auc_score(y_testc, nb_proba2[:,1])\n",
    "    plt.plot(fpr, tpr, color='b',\n",
    "             lw=lw, label='Naive Bayes-CF, auc=%.3f' % auc_nbc)\n",
    "\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='k', lw=lw, linestyle='--')\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=13)\n",
    "    plt.ylabel('True Positive Rate', fontsize=13)\n",
    "    plt.title('Receiver Operating Characteristic', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    #plt.savefig(\"roc.jpeg\",dpi=300,bbox_inches=\"tight\")\n",
    "# plot_roc_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df.summary = df.summary.fillna(\"\")\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = pd.DataFrame(df[[\"info\",\"summary\"]].astype(\"str\").apply(lambda x: \" \".join(x),axis=1),columns=[\"full\"])\n",
    "rec[\"name\"] = df[\"name\"]\n",
    "\n",
    "rec = rec.drop_duplicates()\n",
    "# rec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = df.groupby(\"name\",as_index=False).agg({\"comments\" : lambda x: \" \".join(x)})\n",
    "all_comments = all_comments.drop_duplicates()\n",
    "# all_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = pd.merge(rec, all_comments, how='inner')\n",
    "rec.full = rec.full.fillna(\"\")\n",
    "# rec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = rec.drop_duplicates()\n",
    "# rec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = pd.DataFrame(rec[[\"comments\",\"full\"]].astype(\"str\").apply(lambda x: \" \".join(x),axis=1),columns=[\"full\"])\n",
    "rc[\"name\"] =rec[\"name\"]\n",
    "\n",
    "rc = rc.drop_duplicates()\n",
    "# rc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rc = rc.drop_duplicates(subset=[\"name\"])\n",
    "rc[\"name\"] =rec[\"name\"]\n",
    "\n",
    "# rc.full.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words=\"english\",min_df=1,max_df=.85,ngram_range=(1, 3), token_pattern=\"\\\\b[a-z][a-z][a-z]+\\\\b\")\n",
    "\n",
    "# TfIdf matrix\n",
    "matrix = tfidf_vec.fit_transform(rc.full)\n",
    "# Compute the cosine similarity\n",
    "cosine_sim = linear_kernel(matrix, matrix)\n",
    "\n",
    "import pickle\n",
    "with open('cosine_sim_mumbai.pickle', 'wb') as handle:\n",
    "    pickle.dump(cosine_sim, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(rc.name)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices.to_csv(\"indices_mumbai.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "indices = pd.read_csv(\"indices_mumbai.csv\")\n",
    "\n",
    "indices = indices[\"name\"]\n",
    "# indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rc = rc.reset_index()\n",
    "\n",
    "def get_recommendation(title, cosine_sim ,top_n):\n",
    "    \n",
    "    '''\n",
    "    I choose the restaurant which is not null restaurant information\n",
    "    '''    \n",
    "    recommended_restaurant = []    \n",
    "    # restaurant match indices\n",
    "    idx = indices[indices == title].index[0]\n",
    "    # similarity scores\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "    # top n\n",
    "    top_n_indexes = list(score_series.iloc[1:top_n+1].index)\n",
    "    for i in top_n_indexes:\n",
    "        recommended_restaurant.append(list(indices)[i])\n",
    "        \n",
    "    return recommended_restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation(\" Alav\", cosine_sim ,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Just Reviews\n",
    "\n",
    "rec = df.groupby(\"name\",as_index=False).agg({\"comments\": lambda x: \" \".join(x)})\n",
    "\n",
    "rec.comments = rec.comments.map(remove_stopwords) \n",
    "rec.comments = rec.comments.apply(remove_blank_space)\n",
    "rec.comments = rec.comments.apply(lambda metin: lem_words(metin))\n",
    "rec.comments = rec.comments.apply(lambda metin: lem_words(metin))\n",
    "rec.comments = rec.comments.map(alphanumeric).map(punc_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = rec.reset_index()\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(stop_words=\"english\",min_df=4,max_df=.85, token_pattern=\"\\\\b[a-z][a-z][a-z]+\\\\b\")\n",
    "\n",
    "# TfIdf matrix\n",
    "matrix = tfidf_vec.fit_transform(rec.comments)\n",
    "# Compute the cosine similarity\n",
    "cosine_sim = linear_kernel(matrix, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(rec.name)\n",
    "\n",
    "# get_recommendation(\" Pan Asian\", cosine_sim ,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
